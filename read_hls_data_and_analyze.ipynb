{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import time\n",
    "import os\n",
    "import pandas\n",
    "import requests\n",
    "import boto3\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "import rasterio as rio\n",
    "from rasterio.session import AWSSession\n",
    "from rasterio.plot import show\n",
    "import rioxarray"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get credentials\n",
    "s3_cred_endpoint = 'https://data.lpdaac.earthdatacloud.nasa.gov/s3credentials'\n",
    "def get_temp_creds():\n",
    "    temp_creds_url = s3_cred_endpoint\n",
    "    return requests.get(temp_creds_url).json()\n",
    "\n",
    "temp_creds_req = get_temp_creds()\n",
    "\n",
    "session = boto3.Session(aws_access_key_id=temp_creds_req['accessKeyId'], \n",
    "                        aws_secret_access_key=temp_creds_req['secretAccessKey'],\n",
    "                        aws_session_token=temp_creds_req['sessionToken'],\n",
    "                        region_name='us-west-2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rio_env = rio.Env(AWSSession(session),\n",
    "                  GDAL_DISABLE_READDIR_ON_OPEN='EMPTY_DIR',\n",
    "                  GDAL_HTTP_COOKIEFILE=os.path.expanduser('~/cookies.txt'),\n",
    "                  GDAL_HTTP_COOKIEJAR=os.path.expanduser('~/cookies.txt'))\n",
    "rio_env.__enter__()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the .csv file with S3 links\n",
    "stack_df = pandas.read_csv('/home/jovyan/nch21_hls_timeseries/HLS_data/T13TDE/stack.csv')\n",
    "stack_df = stack_df.loc[~stack_df['date'].isna(), :]\n",
    "stack_df.reset_index(inplace=True)\n",
    "stack_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# subset the s3 links by band\n",
    "header = ['label', 'L30_band', 'S30_band', 'read']\n",
    "data = [\n",
    "    ['coastal_aerosol', 'B01', 'B01', False],\n",
    "    ['blue', 'B02', 'B02', True],\n",
    "    ['green', 'B03', 'B03', True],\n",
    "    ['red', 'B04', 'B04', True],\n",
    "    ['red-edge_1', None, 'B05', False],\n",
    "    ['red-edge_2', None, 'B06', False],\n",
    "    ['red-edge_3', None, 'B07', False],\n",
    "    ['nir_broad', None, 'B08', False],\n",
    "    ['nir', 'B05', 'B8A', True],\n",
    "    ['swir_1', 'B06', 'B11', True],\n",
    "    ['swir_2', 'B07', 'B12', True],\n",
    "    ['water_vapor', None, 'B09', False],\n",
    "    ['cirrus', 'B09', 'B10', False],\n",
    "    ['thermal_infrared_1', 'B10', None, False],\n",
    "    ['thermal_infrared_2', 'B11', None, False],\n",
    "    ['fmask', 'Fmask', 'Fmask', True]\n",
    "]\n",
    "\n",
    "band_df = pandas.DataFrame(data, columns=header)\n",
    "band_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "chunks=dict(band=1, x=256, y=256)\n",
    "\n",
    "hls_ds = None\n",
    "\n",
    "for i in range(0, band_df.shape[0]):\n",
    "    if band_df.loc[i, 'read'] == True:\n",
    "        # subset stack for links for each band\n",
    "        band_stack = stack_df.loc[\n",
    "        ((stack_df['band'] == band_df.loc[i,'L30_band']) & (stack_df['sensor'] == 'L30')) |\n",
    "        ((stack_df['band'] == band_df.loc[i,'S30_band']) & (stack_df['sensor'] == 'S30')), :]\n",
    "        \n",
    "        # create the time index\n",
    "        band_time = [datetime.strptime(str(t), '%Y%jT%H%M%S') for t in band_stack['date']]\n",
    "        xr.Variable('time', band_time)\n",
    "\n",
    "        #s3_links = band_stack['S3_links']\n",
    "        s3_links = band_stack['local_links']\n",
    "        \n",
    "        # get the band label\n",
    "        band_label = band_df.loc[i, 'label']\n",
    "        \n",
    "        # open the links\n",
    "        hls_ts_da = xr.concat([rioxarray.open_rasterio(f, chunks=chunks).squeeze('band', drop=True) for f in s3_links], dim=band_time)\n",
    "        hls_ts_da = hls_ts_da.rename({'concat_dim':'time'})\n",
    "        \n",
    "        if hls_ds is None:\n",
    "            hls_ds = xr.Dataset({band_label: hls_ts_da})\n",
    "        else:\n",
    "            hls_ds[band_label] = hls_ts_da\n",
    "\n",
    "#hls_ds.rename({'concat_dim':'time'})\n",
    "hls_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "def SI(b1, b2):\n",
    "    si = (b1 - b2) / (b1 + b2)\n",
    "    si = xr.where(si < -1.0, -1.0, si)\n",
    "    si = xr.where(si > 1.0, 1.0, si)\n",
    "    si = xr.where(np.isfinite(si), si, np.nan)\n",
    "    return(si)\n",
    "\n",
    "# calculate NDVI (normalized difference vegetation index)\n",
    "hls_ds['ndvi'] = SI(hls_ds['nir'], hls_ds['red'])\n",
    "\n",
    "# calculate NBR (normalized difference burn ratio)\n",
    "hls_ds['nbr'] = SI(hls_ds['nir'], hls_ds['swir_2'])\n",
    "\n",
    "# calculate NDWI (normalized difference water index)\n",
    "hls_ds['ndwi_gao'] = SI(hls_ds['nir'], hls_ds['swir_1'])\n",
    "hls_ds['ndwi_mcfeeters'] = SI(hls_ds['green'], hls_ds['nir'])\n",
    "\n",
    "# calculate NDSI (normalized difference snow index)\n",
    "hls_ds['ndsi'] = SI(hls_ds['green'], hls_ds['swir_1'])\n",
    "\n",
    "hls_ds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "da = hls_ds['nbr']\n",
    "\n",
    "roll = da.rolling(time = 5, min_periods=5, center = True)\n",
    "roll\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test = roll.mean(keep_attrs=False)\n",
    "test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import geoviews as gv\n",
    "import hvplot.xarray\n",
    "\n",
    "# nbr_i.hvplot(x='x', y='y', cmap='viridis', title='NBR') + \\\n",
    "# roll_nbr_i.hvplot(x='x', y='y', cmap='viridis', title='roll NBR')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=20\n",
    "nbr_i = da[i, :, :]\n",
    "nbr_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roll_nbr_i = test[i, :, :]\n",
    "roll_nbr_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#roll_nbr_i.hvplot(x='x', y='y', cmap='viridis', title='roll NBR')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#nbr_i.hvplot(x='x', y='y', cmap='viridis', title='NBR')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
